import random
random.seed(42)
import os
import sys
import argparse
from tqdm import tqdm
import time
import json
import numpy as np

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°Pythonè·¯å¾„
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.insert(0, project_root)

from utils.utils import (
    load_pkl, save_pkl, call_model_api, compute_metrics,
    get_confidence_voting, get_cached_embedding, find_similar_cases,
    get_comprehensive_similarity, string2token_nums
)

# æ°´å°ç³»ç»Ÿæ ¸å¿ƒç»„ä»¶
from utils.utils import (
    make_prompt_for_watermark_generation,
    generation_by_qwen,
    make_prompt_for_detection,
    convert_to_detector_examples,
    identify_watermark_effectiveness
)

# ==================== å¿«é€Ÿé…ç½®å¼€å…³ ====================
# ä¿®æ”¹è¿™äº›å˜é‡æ¥æ§åˆ¶ç³»ç»Ÿè¡Œä¸º
USE_CONFIDENCE = False       # æ”¹ä¸º False ç¦ç”¨ç½®ä¿¡åº¦
FAST_MODE = False           # æ”¹ä¸º True å¯ç”¨å¿«é€Ÿæ¨¡å¼
DEBUG_MODE = False          # æ”¹ä¸º True å¯ç”¨è°ƒè¯•æ¨¡å¼

# æ ¹æ®æ¨¡å¼è‡ªåŠ¨è°ƒæ•´è®¾ç½®
if DEBUG_MODE:
    USE_CONFIDENCE = False
    MAX_EPOCHS = 2
    MAX_EXAMPLES_SIZE = 20
    print("ğŸ› è°ƒè¯•æ¨¡å¼å·²å¯ç”¨")
elif FAST_MODE:
    USE_CONFIDENCE = False
    MAX_EPOCHS = 5
    MAX_EXAMPLES_SIZE = 100
    print("âš¡ å¿«é€Ÿæ¨¡å¼å·²å¯ç”¨")
else:
    MAX_EPOCHS = 2
    MAX_EXAMPLES_SIZE = 200
    print("ğŸ¯ æ ‡å‡†æ¨¡å¼å·²å¯ç”¨")

# ç³»ç»Ÿé…ç½®
MAX_PROMPT_EXAMPLES = 10  # promptä¸­ä½¿ç”¨çš„æœ€å¤§ç¤ºä¾‹æ•°

# æ¡ˆä¾‹è´¨é‡è¯„ä¼°æƒé‡
LABEL_WEIGHT = 0.8  # æ ‡ç­¾æƒé‡
CONFIDENCE_WEIGHT = 0.2  # ç½®ä¿¡åº¦æƒé‡
QUALITY_THRESHOLD = 0.6  # æ¡ˆä¾‹è´¨é‡é˜ˆå€¼
SIMILARITY_THRESHOLD = 0.7  # æœ€ä½ç›¸ä¼¼åº¦è¦æ±‚

# æ˜¾ç¤ºå½“å‰è®¾ç½®
print(f"ç½®ä¿¡åº¦ç³»ç»Ÿ: {'âœ… å¯ç”¨' if USE_CONFIDENCE else 'âŒ ç¦ç”¨'}")
print(f"è®­ç»ƒè½®æ•°: {MAX_EPOCHS}")
print("-" * 40)

def calculate_case_quality_score(case):
    """
    æ”¹è¿›çš„è´¨é‡è¯„åˆ†ï¼Œä½¿ç”¨æ›´å‡†ç¡®çš„æ–‡æœ¬ç›¸ä¼¼åº¦è®¡ç®—
    :param case: EnhancedCaseå®ä¾‹
    :return: 0.0-1.0ä¹‹é—´çš„è´¨é‡åˆ†æ•°
    """
    # æ°´å°å¼ºåº¦å¾—åˆ† - ä½¿ç”¨ç½®ä¿¡åº¦ç›´æ¥ä½œä¸ºæ°´å°å¼ºåº¦çš„åº¦é‡
    watermark_strength = case.confidence
    
    # åŸæ–‡æ­£ç¡®åˆ†ç±»å¾—åˆ†
    original_detection_score = 1.0 if getattr(case, 'original_correctly_identified', False) else 0.0
    
    # ä½¿ç”¨æ”¹è¿›çš„ç›¸ä¼¼åº¦è®¡ç®—æ–¹æ³•
    try:
        similarity_score = get_comprehensive_similarity(case.original, case.watermarked)
    except Exception as e:
        # å¦‚æœæ–°å‡½æ•°ä¸å¯ç”¨ï¼Œä½¿ç”¨ç®€å•çš„ç›¸ä¼¼åº¦è®¡ç®—
        print(f"ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨ç®€å•æ–¹æ³•: {e}")
        len_ratio = min(len(case.watermarked), len(case.original)) / max(len(case.watermarked), len(case.original))
        similarity_score = len_ratio
    
    # è°ƒæ•´æƒé‡ - å¢åŠ ç›¸ä¼¼åº¦çš„é‡è¦æ€§
    w1, w2, w3 = 0.4, 0.2, 0.4  # æ°´å°å¼ºåº¦æƒé‡, åŸæ–‡è¯†åˆ«æƒé‡, ç›¸ä¼¼åº¦æƒé‡
    quality_score = (w1 * watermark_strength) + (w2 * original_detection_score) + (w3 * similarity_score)
    
    return quality_score

def check_original_classification(original_text, detector_examples, use_confidence=True):
    """
    æ£€æŸ¥åŸæ–‡æ˜¯å¦è¢«æ­£ç¡®åˆ†ç±»ä¸ºOriginal
    :param original_text: åŸå§‹æ–‡æœ¬
    :param detector_examples: æ£€æµ‹å™¨ç¤ºä¾‹
    :param use_confidence: æ˜¯å¦ä½¿ç”¨ç½®ä¿¡åº¦
    :return: æ˜¯å¦æ­£ç¡®åˆ†ç±»
    """
    try:
        if use_confidence:
            # ä½¿ç”¨ç½®ä¿¡åº¦æŠ•ç¥¨
            original_confidence = get_confidence_voting(
                original_text,
                detector_examples,
                rounds=3
            )
            # ä½ç½®ä¿¡åº¦è¡¨ç¤ºè¢«è¯†åˆ«ä¸ºåŸå§‹æ–‡æœ¬
            predicted_original = original_confidence < 0.5
        else:
            # ä¸ä½¿ç”¨ç½®ä¿¡åº¦æ—¶ï¼Œç›´æ¥è¿›è¡Œå•æ¬¡æ£€æµ‹
            prompt = make_prompt_for_detection(original_text, detector_examples)
            response = call_model_api(prompt).lower()
            predicted_original = 'original' in response
        
        return predicted_original
    except Exception as e:
        print(f"æ£€æŸ¥åŸæ–‡åˆ†ç±»æ—¶å‡ºé”™: {e}")
        return False

def filter_by_similarity(case, similarity_threshold=SIMILARITY_THRESHOLD):
    """
    æ ¹æ®ç›¸ä¼¼åº¦ç­›é€‰æ¡ˆä¾‹
    :param case: EnhancedCaseå®ä¾‹
    :param similarity_threshold: ç›¸ä¼¼åº¦é˜ˆå€¼
    :return: æ˜¯å¦é€šè¿‡ç­›é€‰
    """
    try:
        similarity = get_comprehensive_similarity(case.original, case.watermarked)
        return similarity >= similarity_threshold
    except Exception as e:
        # å¦‚æœè®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨åŸæ¥çš„é•¿åº¦æ¯”æ–¹æ³•
        print(f"ç›¸ä¼¼åº¦è®¡ç®—å¤±è´¥ï¼Œä½¿ç”¨é•¿åº¦æ¯”æ–¹æ³•: {e}")
        len_ratio = min(len(case.watermarked), len(case.original)) / max(len(case.watermarked), len(case.original))
        return len_ratio >= 0.8  # ä¿å®ˆçš„é•¿åº¦ç›¸ä¼¼åº¦è¦æ±‚

class EnhancedCase:
    """å¢å¼ºå‹æ¡ˆä¾‹ç±»ï¼ŒåŒ…å«ç½®ä¿¡åº¦å’ŒåµŒå…¥å‘é‡"""
    def __init__(self, original, watermarked, label=None, confidence=0.0):
        self.original = original
        self.watermarked = watermarked
        self.label = label  # 'Good' æˆ– 'Bad'
        self.confidence = confidence
        self.embedding = None
        self.quality_score = 0.0  # æ–°å¢ï¼šæ¡ˆä¾‹è´¨é‡åˆ†æ•°
        # è®¡ç®—åµŒå…¥å‘é‡
        self.update_embedding()
    
    def update_embedding(self):
        """æ›´æ–°åµŒå…¥å‘é‡"""
        self.embedding = get_cached_embedding(self.original)
    
    def update_confidence_and_label(self, detector_examples, use_confidence=True):
        """åˆ†ç¦»æ°´å°æ–‡æœ¬æ£€æµ‹è¯„ä¼°å’ŒåŸæ–‡è¯„ä¼°"""
        if use_confidence:
            # å•ç‹¬è¯„ä¼°æ°´å°æ–‡æœ¬çš„æ£€æµ‹æ•ˆæœ
            watermark_confidence = get_confidence_voting(
                self.watermarked, 
                detector_examples,
                rounds=5  # é»˜è®¤5è½®æŠ•ç¥¨
           )
        
            # å•ç‹¬è¯„ä¼°åŸæ–‡æ˜¯å¦è¢«æ­£ç¡®è¯†åˆ«ä¸ºéæ°´å°
            original_confidence = get_confidence_voting(
                self.original,
                detector_examples,
                rounds=3  # åŸæ–‡æ£€æµ‹å¯ä»¥ä½¿ç”¨è¾ƒå°‘è½®æ•°
            )
        
            # è®°å½•åŸæ–‡æ˜¯å¦è¢«æ­£ç¡®è¯†åˆ«ä¸º"Original"
            self.original_correctly_identified = original_confidence < 0.3  # ä½ç½®ä¿¡åº¦è¡¨ç¤ºè¢«è¯†åˆ«ä¸ºåŸå§‹æ–‡æœ¬
        
            # æ›´æ–°æ°´å°æ–‡æœ¬çš„æ ‡ç­¾å’Œç½®ä¿¡åº¦
            self.watermark_detected = watermark_confidence > 0.6  # æ°´å°æ£€æµ‹é˜ˆå€¼
            self.confidence = watermark_confidence
            
            # ç»¼åˆåˆ¤æ–­æ ‡ç­¾
            if self.watermark_detected:
                self.label = 'Good'
            else:
                self.label = 'Bad'
                # å¦‚æœæ°´å°æœªè¢«æ£€æµ‹åˆ°ï¼Œé™ä½ç½®ä¿¡åº¦ä½†ä¸ä¸ºé›¶
                self.confidence = watermark_confidence * 0.3
            
            # å­˜å‚¨é¢å¤–ä¿¡æ¯ä»¥ä¾›åˆ†æ
            self.watermark_confidence = watermark_confidence
            self.original_confidence = original_confidence
        else:
            # ä¸ä½¿ç”¨ç½®ä¿¡åº¦æ—¶ï¼Œä½¿ç”¨ç®€å•çš„äºŒåˆ†ç±»æ–¹æ³•
            # åªè¿›è¡Œä¸€æ¬¡æ£€æµ‹ï¼Œä¸ç”¨å¤šè½®æŠ•ç¥¨
            prompt = make_prompt_for_detection(self.watermarked, detector_examples)
            watermark_response = call_model_api(prompt).lower()
            
            prompt_orig = make_prompt_for_detection(self.original, detector_examples)
            original_response = call_model_api(prompt_orig).lower()
            
            # ç›´æ¥æ ¹æ®æ£€æµ‹ç»“æœè®¾ç½®æ ‡ç­¾
            self.watermark_detected = 'watermarked' in watermark_response
            self.original_correctly_identified = 'original' in original_response
            
            if self.watermark_detected and self.original_correctly_identified:
                self.label = 'Good'
                self.confidence = 1.0  # ä¸ä½¿ç”¨ç½®ä¿¡åº¦æ—¶è®¾ä¸ºå›ºå®šå€¼
            else:
                self.label = 'Bad'
                self.confidence = 0.0  # ä¸ä½¿ç”¨ç½®ä¿¡åº¦æ—¶è®¾ä¸ºå›ºå®šå€¼
            
            # å­˜å‚¨é¢å¤–ä¿¡æ¯ä»¥ä¾›åˆ†æ
            self.watermark_confidence = 1.0 if self.watermark_detected else 0.0
            self.original_confidence = 0.0 if self.original_correctly_identified else 1.0
        
        # æ›´æ–°è´¨é‡åˆ†æ•°
        self.quality_score = calculate_case_quality_score(self)
    
    def to_dict(self):
        """è½¬æ¢ä¸ºå­—å…¸ï¼Œæ–¹ä¾¿ä¿å­˜"""
        return {
            'original': self.original,
            'watermarked': self.watermarked,
            'label': self.label,
            'confidence': self.confidence,
            'quality_score': self.quality_score
        }
    
    @classmethod
    def from_dict(cls, data):
        """ä»å­—å…¸åˆ›å»ºæ¡ˆä¾‹å¯¹è±¡"""
        case = cls(
            data['original'], 
            data['watermarked'], 
            data.get('label', None),
            data.get('confidence', 0.0)
        )
        case.quality_score = data.get('quality_score', 0.0)
        return case

def enhanced_to_basic_examples(enhanced_examples):
    """å°†å¢å¼ºå‹æ¡ˆä¾‹è½¬æ¢ä¸ºåŸºæœ¬å­—å…¸æ ¼å¼"""
    basic_examples = {"success": [], "failure": []}
    
    # å¤„ç†æˆåŠŸæ¡ˆä¾‹
    for case in enhanced_examples["success"]:
        if isinstance(case, EnhancedCase):
            basic_examples["success"].append(case.to_dict())
        else:
            basic_examples["success"].append(case)
    
    # å¤„ç†å¤±è´¥æ¡ˆä¾‹
    for case in enhanced_examples["failure"]:
        if isinstance(case, EnhancedCase):
            basic_examples["failure"].append(case.to_dict())
        else:
            basic_examples["failure"].append(case)
    
    return basic_examples

def show_simple_text_diff(original, watermarked, case_id=None):
    """æœ€ç®€å•çš„å·®å¼‚æ˜¾ç¤º"""
    orig_words = original.split()
    water_words = watermarked.split()
    
    # æ‰¾å‡ºä¸åŒçš„è¯
    orig_set = set(orig_words)
    water_set = set(water_words)
    
    removed = orig_set - water_set
    added = water_set - orig_set
    
    prefix = f"æ¡ˆä¾‹{case_id}: " if case_id else ""
    
    # æ˜¾ç¤ºåŸæ–‡ï¼ˆæ ‡è®°åˆ é™¤çš„è¯ï¼‰
    orig_display = []
    for word in orig_words:
        if word in removed:
            orig_display.append(f"[åˆ é™¤:{word}]")
        else:
            orig_display.append(word)
    
    # æ˜¾ç¤ºæ°´å°æ–‡æœ¬ï¼ˆæ ‡è®°æ·»åŠ çš„è¯ï¼‰
    water_display = []
    for word in water_words:
        if word in added:
            water_display.append(f"[æ·»åŠ :{word}]")
        else:
            water_display.append(word)
    
    print(f"{prefix}åŸå§‹: {' '.join(orig_display)}")
    print(f"{prefix}æ°´å°: {' '.join(water_display)}")
    
    # æ˜¾ç¤ºå˜åŒ–ç»Ÿè®¡
    if removed or added:
        changes = []
        if removed:
            changes.append(f"åˆ é™¤{len(removed)}è¯")
        if added:
            changes.append(f"æ·»åŠ {len(added)}è¯")
        print(f"{prefix}å˜åŒ–: {', '.join(changes)}")
    else:
        print(f"{prefix}å˜åŒ–: æ— æ˜æ˜¾è¯æ±‡å˜åŒ–")
    print()

def main():
    parser = argparse.ArgumentParser(description='å¯¹æŠ—å¼æ°´å°ç”Ÿæˆä¸æ£€æµ‹ç³»ç»Ÿ')
    parser.add_argument('--data_dir', type=str, default='../../data/',
                       help='æ•°æ®é›†ç›®å½•è·¯å¾„')
    parser.add_argument('--model', type=str, default='qwen-turbo',
                       choices=['qwen-turbo', 'gpt-3.5-turbo'],
                       help='ä½¿ç”¨çš„ç”Ÿæˆæ¨¡å‹')
    parser.add_argument('--output_dir', type=str, default='../results/',
                       help='ç»“æœè¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    # æ£€æŸ¥è¾“å‡ºç›®å½•
    if not os.path.exists(args.output_dir):
        os.makedirs(args.output_dir)
        print(f"åˆ›å»ºè¾“å‡ºç›®å½•: {args.output_dir}")

    # åˆå§‹åŒ–ç³»ç»Ÿ
    enhanced_examples = {"success": [], "failure": []}
    performance_log = []

    # åŠ è½½åŸå§‹æ•°æ®é›†
    dataset_path = os.path.join(args.data_dir, "common", "train", "train_humans.pkl")
    dataset_path = os.path.normpath(dataset_path)  # ä¿®å¤è·¯å¾„åˆ†éš”ç¬¦
    
    # æ£€æŸ¥æ•°æ®æ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not os.path.exists(dataset_path):
        print(f"âš ï¸  æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {dataset_path}")
        print("ğŸ¯ ç”Ÿæˆæ¨¡æ‹Ÿæ•°æ®è¿›è¡Œæµ‹è¯•...")
        # ç”Ÿæˆä¸€äº›æ¨¡æ‹Ÿæ•°æ®ç”¨äºæµ‹è¯•
        original_texts = [
            f"This is a sample human-written text {i}. It contains natural language patterns and typical human writing characteristics."
            for i in range(10)
        ]
    else:
        original_texts = load_pkl(dataset_path)
        original_texts = original_texts[:1000]  # å†³å®šä½¿ç”¨æ–‡ç« èŒƒå›´
    
    print(f"åŠ è½½äº† {len(original_texts)} ç¯‡åŸå§‹æ–‡ç« ")

    # å¯¹æŠ—è®­ç»ƒä¸»å¾ªç¯
    for epoch in range(MAX_EPOCHS):
        print(f"\n=== ç¬¬ {epoch+1}/{MAX_EPOCHS} è½®è®­ç»ƒ ===")
        epoch_metrics = {"success": 0, "failure": 0}
        
        # åˆå§‹åŒ–æœ¬è½®çš„æ ‡ç­¾å’Œé¢„æµ‹åˆ—è¡¨
        labels, preds = [], []
        
        # è®°å½•å½“å‰å¤„ç†çš„æ ·æœ¬ä½ç½®
        current_position = 0
        total_samples = len(original_texts)
        
        # è®¡ç®—5%çš„æ ·æœ¬æ•°é‡ï¼Œç¡®ä¿è‡³å°‘ä¸º1
        display_interval = max(1, int(total_samples * 0.05))
        
        # åˆ›å»ºç¬¬ä¸€ä¸ªè¿›åº¦æ¡
        pbar = tqdm(range(total_samples), total=total_samples, desc=f"ç¬¬{epoch+1}è½®")
        
        for idx, original_text in enumerate(original_texts):
            # æ›´æ–°è¿›åº¦æ¡
            pbar.update(1)
            current_position += 1
            
            # è½¬æ¢ä¸ºåŸºæœ¬å­—å…¸æ ¼å¼ç”¨äºç°æœ‰å‡½æ•°
            basic_examples = enhanced_to_basic_examples(enhanced_examples)
            
            # ç”Ÿæˆæ°´å°æ–‡æœ¬ - ç›´æ¥ä½¿ç”¨make_prompt_for_watermark_generationï¼Œå®ƒå·²ç»å®ç°äº†ç›¸ä¼¼åº¦é€‰æ‹©
            prompt_gen = make_prompt_for_watermark_generation(
                original_text, basic_examples, max_examples=MAX_PROMPT_EXAMPLES
            )
            orig_tokens = string2token_nums(original_text)  # å•ç‹¬è®¡ç®—åŸæ–‡tokenæ•°
            
            watermarked_text = generation_by_qwen(prompt_gen, orig_tokens)

            # è½¬æ¢æ£€æµ‹å™¨ç¤ºä¾‹
            detector_examples = convert_to_detector_examples(basic_examples)
            
            # åˆ›å»ºå¢å¼ºå‹æ¡ˆä¾‹
            new_case = EnhancedCase(original_text, watermarked_text)
            
            # åŒæ—¶æ›´æ–°æ ‡ç­¾å’Œç½®ä¿¡åº¦ï¼Œç¡®ä¿ä¸€è‡´æ€§
            try:
                new_case.update_confidence_and_label(detector_examples, use_confidence=USE_CONFIDENCE)
            except Exception as e:
                print(f"æ ‡ç­¾å’Œç½®ä¿¡åº¦æ›´æ–°å¤±è´¥: {e}")
                new_case.label = 'Bad'
                new_case.confidence = 0.3  # å¤±è´¥æ—¶ä½¿ç”¨è¾ƒä½çš„é»˜è®¤ç½®ä¿¡åº¦
                new_case.quality_score = calculate_case_quality_score(new_case)
            
            # è®°å½•æ£€æµ‹ç»“æœ - ç”¨äºçœŸå®è¯„ä¼°
            # æ³¨æ„ï¼šè¿™é‡Œä½¿ç”¨äºŒåˆ†ç±»æ ‡ç­¾ç”¨äºè¯„ä¼°ï¼Œè€Œä¸æ˜¯"Good"/"Bad"
            if new_case.label == 'Good':
                labels.append("1")  # æ°´å°æˆåŠŸ (é¢„æœŸæ˜¯Watermarked)
                preds.append("1")   # é¢„æµ‹ä¸ºWatermarked
            else:
                labels.append("1")  # æ°´å°å¤±è´¥ (é¢„æœŸæ˜¯Watermarkedä½†æœªè¢«æ­£ç¡®æ£€æµ‹)
                preds.append("0")   # é¢„æµ‹ä¸ºOriginal

            # æ¯å¤„ç†5%çš„æ ·æœ¬æ˜¾ç¤ºä¸€æ¬¡è¯¦ç»†è¿‡ç¨‹
            if idx % display_interval == 0:
                current_percent = (idx / total_samples) * 100
                print(f"\n--- ç¬¬{epoch+1}è½® {current_percent:.1f}% è¿›åº¦è¯¦ç»†è¿‡ç¨‹ ---")
                print(f"æ ·æœ¬ç´¢å¼•: {idx}/{total_samples}")
                show_simple_text_diff(original_text, watermarked_text, case_id=idx+1)
                print(f"æ ‡ç­¾åˆ†ç±»: {new_case.label} (Good=æˆåŠŸæ°´å°ï¼ŒBad=å¤±è´¥æ°´å°)")
                print(f"ç½®ä¿¡åº¦: {new_case.confidence:.2%}")
                print(f"è´¨é‡åˆ†æ•°: {new_case.quality_score:.2%} (æ ‡ç­¾æƒé‡={LABEL_WEIGHT}, ç½®ä¿¡åº¦æƒé‡={CONFIDENCE_WEIGHT})")
                print("----------------------------\n")

            # ä½¿ç”¨åŠ æƒè´¨é‡åˆ†æ•°å†³å®šæ¡ˆä¾‹åˆ†ç±»
            if new_case.quality_score >= QUALITY_THRESHOLD:
                enhanced_examples["success"].append(new_case)
                epoch_metrics["success"] += 1
            else:
                enhanced_examples["failure"].append(new_case)
                epoch_metrics["failure"] += 1

            # å¯¹successåˆ—è¡¨æŒ‰è´¨é‡åˆ†æ•°æ’åº
            enhanced_examples["success"].sort(key=lambda x: x.quality_score, reverse=True)
            
            # ä¿ç•™è´¨é‡åˆ†æ•°æœ€é«˜çš„MAX_EXAMPLES_SIZEä¸ªæ¡ˆä¾‹
            if len(enhanced_examples["success"]) > MAX_EXAMPLES_SIZE:
                enhanced_examples["success"] = enhanced_examples["success"][:MAX_EXAMPLES_SIZE]

            # ä¿å­˜æ£€æŸ¥ç‚¹ - è½¬æ¢ä¸ºåŸºæœ¬æ ¼å¼åä¿å­˜
            if (idx + 1) % 50 == 0 or idx == len(original_texts) - 1:
                checkpoint_examples = enhanced_to_basic_examples(enhanced_examples)
                save_pkl(checkpoint_examples, os.path.join(args.output_dir, f"checkpoint_{epoch}.pkl"))
            
            # æ¯éš”Nä¸ªæ ·æœ¬ï¼Œæ·»åŠ ä¸€ä¸ª"åŸå§‹"æ ·æœ¬è¿›è¡Œæµ‹è¯•
            if idx % 5 == 0:  # æ¯5ä¸ªæ ·æœ¬æ·»åŠ ä¸€ä¸ªåŸå§‹æ–‡æœ¬æ£€æµ‹æ¡ˆä¾‹
                # éšæœºé€‰æ‹©ä¸€ç¯‡ä¸åŒçš„æ–‡ç« ä½œä¸ºåŸå§‹æ ·æœ¬
                random_idx = random.randint(0, len(original_texts)-1)
                while random_idx == idx:  # ç¡®ä¿ä¸æ˜¯å½“å‰å¤„ç†çš„æ–‡ç« 
                    random_idx = random.randint(0, len(original_texts)-1)
                
                test_original = original_texts[random_idx]
                
                # è¯„ä¼°æ£€æµ‹å™¨å¯¹åŸå§‹æ–‡æœ¬çš„è¯†åˆ«èƒ½åŠ›
                if USE_CONFIDENCE:
                    original_confidence = get_confidence_voting(
                        test_original,
                        detector_examples,
                        rounds=3
                    )
                    predicted_original = original_confidence < 0.5
                else:
                    # ä¸ä½¿ç”¨ç½®ä¿¡åº¦æ—¶ï¼Œç›´æ¥è¿›è¡Œå•æ¬¡æ£€æµ‹
                    prompt = make_prompt_for_detection(test_original, detector_examples)
                    response = call_model_api(prompt).lower()
                    predicted_original = 'original' in response
                    original_confidence = 0.0 if predicted_original else 1.0  # æ¨¡æ‹Ÿç½®ä¿¡åº¦ç”¨äºæ˜¾ç¤º
                
                # è®°å½•è¯„ä¼°ç»“æœ
                labels.append("0")  # çœŸå®æ ‡ç­¾ä¸ºåŸå§‹æ–‡æœ¬
                preds.append("0" if predicted_original else "1")  # é¢„æµ‹
                
                # æ‰“å°è¯¦ç»†ä¿¡æ¯ï¼ˆå¦‚æœåœ¨æ˜¾ç¤ºé—´éš”å†…ï¼‰
                if idx % display_interval == 0:
                    print(f"\n--- åŸå§‹æ–‡æœ¬æ£€æµ‹æµ‹è¯• ---")
                    print(f"åŸå§‹æ–‡æœ¬: {test_original[:500]}...")
                    print(f"æ£€æµ‹ç½®ä¿¡åº¦: {original_confidence:.2%}")
                    print(f"é¢„æµ‹ç»“æœ: {'Original' if predicted_original else 'Watermarked'}")
                    print(f"ä½¿ç”¨ç½®ä¿¡åº¦: {'æ˜¯' if USE_CONFIDENCE else 'å¦'}")
                    print("----------------------------\n")
                
            # è®¡ç®—å½“å‰æŒ‡æ ‡
            if len(labels) > 0:
                acc = sum([1 for l, p in zip(labels, preds) if l == p]) / len(labels)
                wm_rec = sum([1 for l, p in zip(labels, preds) if l == p == "1"]) / labels.count("1") if labels.count("1") > 0 else 0
                high_quality = len([c for c in enhanced_examples["success"] if c.quality_score > 0.8])
                
                # æ›´æ–°è¿›åº¦æ¡ä¿¡æ¯
                pbar.set_postfix({
                    'acc': f"{acc:.2%}",
                    'w_rec': f"{wm_rec:.2%}",
                    'high_q': high_quality
                })
            
            # æ¯5ä¸ªæ ·æœ¬åä¿ç•™å½“å‰è¿›åº¦æ¡å¹¶åˆ›å»ºæ–°çš„è¿›åº¦æ¡
            if (idx + 1) % 5 == 0 and idx < len(original_texts) - 1:
                # è®¾ç½®å½“å‰è¿›åº¦æ¡ä¸ºä¿ç•™çŠ¶æ€
                pbar.leave = True
                pbar.close()
                
                # åˆ›å»ºæ–°çš„è¿›åº¦æ¡ï¼Œä½†ä»ç„¶è¦†ç›–å…¨éƒ¨æ ·æœ¬
                remaining = total_samples - current_position
                pbar = tqdm(range(remaining), total=total_samples, initial=current_position, 
                           desc=f"ç¬¬{epoch+1}è½® ({current_position}/{total_samples})")
                
                # ç«‹å³è®¾ç½®æŒ‡æ ‡ä¿¡æ¯ä»¥é¿å…ç©ºç™½è¿›åº¦æ¡
                if len(labels) > 0:
                    pbar.set_postfix({
                        'acc': f"{acc:.2%}",
                        'w_rec': f"{wm_rec:.2%}",
                        'high_q': high_quality
                    })

        # ç¡®ä¿æœ€åçš„è¿›åº¦æ¡æ­£ç¡®å…³é—­
        pbar.close()
        
        # è®¡ç®—æœ¬è½®æœ€ç»ˆæŒ‡æ ‡
        human_rec, machine_rec, avg_rec, acc, precision, recall, f1 = compute_metrics(labels, preds)
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼ä»¥åŒ¹é…åŸæœ‰è¾“å‡º
        final_metrics = {
            "accuracy": acc,
            "f1": f1,
            "watermarked_recall": machine_rec / 100,  # åŸå‡½æ•°è¿”å›ç™¾åˆ†æ¯”ï¼Œè½¬æ¢ä¸ºå°æ•°
            "original_recall": human_rec / 100,
            "average_recall": avg_rec / 100
        }
        
        # æ·»åŠ åˆ°æ€§èƒ½æ—¥å¿—
        performance_log.append({
            "epoch": epoch+1,
            "accuracy": f"{final_metrics['accuracy']:.2%}",
            "f1": f"{final_metrics['f1']:.2%}",
            "watermarked_recall": f"{final_metrics['watermarked_recall']:.2%}",
            "original_recall": f"{final_metrics['original_recall']:.2%}",
            "average_recall": f"{final_metrics['average_recall']:.2%}",
            "success_rate": f"{epoch_metrics['success']/len(original_texts):.2%}",
            "high_quality_cases": len([c for c in enhanced_examples["success"] if c.quality_score > 0.8]),
            "avg_quality_score": f"{sum(c.quality_score for c in enhanced_examples['success'])/len(enhanced_examples['success']):.2%}" if enhanced_examples['success'] else "0.00%"
        })

        print(f"\næœ¬è½®è¯„ä¼°æŒ‡æ ‡:")
        print(f"å‡†ç¡®ç‡: {final_metrics['accuracy']:.2%}")
        print(f"F1åˆ†æ•°: {final_metrics['f1']:.2%}")
        print(f"æ°´å°å¬å›ç‡: {final_metrics['watermarked_recall']:.2%}")
        print(f"åŸå§‹æ–‡æœ¬å¬å›ç‡: {final_metrics['original_recall']:.2%}")
        print(f"å¹³å‡å¬å›ç‡: {final_metrics['average_recall']:.2%}")
        print(f"å¹³å‡è´¨é‡åˆ†æ•°: {sum(c.quality_score for c in enhanced_examples['success'])/len(enhanced_examples['success']):.2%}" if enhanced_examples['success'] else "0.00%")
        print(f"é«˜è´¨é‡æ¡ˆä¾‹æ•°(>0.8): {len([c for c in enhanced_examples['success'] if c.quality_score > 0.8])}")

    # æœ€ç»ˆè¯„ä¼°
    print("\n=== æœ€ç»ˆè¯„ä¼° ===")
    basic_examples = enhanced_to_basic_examples(enhanced_examples)
    detector_examples = convert_to_detector_examples(basic_examples)
    
    # è·å–æ‰€æœ‰æ¡ˆä¾‹çš„è´¨é‡åˆ†æ•°åˆ†å¸ƒ
    quality_scores = [case.quality_score for case in enhanced_examples["success"]]
    confidence_levels = [case.confidence for case in enhanced_examples["success"]]
    
    # ä¿å­˜æœ€ç»ˆæŠ¥å‘Š
    final_report = {
        "performance_history": performance_log,
        "quality_distribution": {
            "min": min(quality_scores) if quality_scores else 0,
            "max": max(quality_scores) if quality_scores else 0,
            "mean": sum(quality_scores)/len(quality_scores) if quality_scores else 0,
            "median": sorted(quality_scores)[len(quality_scores)//2] if quality_scores else 0,
            "high_quality_ratio": len([q for q in quality_scores if q > 0.8])/len(quality_scores) if quality_scores else 0
        },
        "confidence_distribution": {
            "min": min(confidence_levels) if confidence_levels else 0,
            "max": max(confidence_levels) if confidence_levels else 0,
            "mean": sum(confidence_levels)/len(confidence_levels) if confidence_levels else 0,
            "median": sorted(confidence_levels)[len(confidence_levels)//2] if confidence_levels else 0,
            "high_conf_ratio": len([c for c in confidence_levels if c > 0.8])/len(confidence_levels) if confidence_levels else 0
        },
        "final_examples_count": {
            "success": len(enhanced_examples["success"]),
            "failure": len(enhanced_examples["failure"])
        },
        "weights_used": {
            "label_weight": LABEL_WEIGHT,
            "confidence_weight": CONFIDENCE_WEIGHT,
            "quality_threshold": QUALITY_THRESHOLD,
            "use_confidence": USE_CONFIDENCE
        }
    }
    
    with open(os.path.join(args.output_dir, "final_report.json"), "w") as f:
        json.dump(final_report, f, indent=2)

    print("\n=== æœ€ç»ˆç»Ÿè®¡ ===")
    print(f"æˆåŠŸæ¡ˆä¾‹æ•°: {len(enhanced_examples['success'])}")
    print(f"å¤±è´¥æ¡ˆä¾‹æ•°: {len(enhanced_examples['failure'])}")
    print(f"é«˜è´¨é‡æ¡ˆä¾‹æ¯”ä¾‹: {final_report['quality_distribution']['high_quality_ratio']:.2%}")
    print(f"å¹³å‡è´¨é‡åˆ†æ•°: {final_report['quality_distribution']['mean']:.2%}")
    print(f"ä½¿ç”¨ç½®ä¿¡åº¦: {'æ˜¯' if USE_CONFIDENCE else 'å¦'}")
    print(f"ä½¿ç”¨çš„æƒé‡è®¾ç½®: æ ‡ç­¾æƒé‡={LABEL_WEIGHT}, ç½®ä¿¡åº¦æƒé‡={CONFIDENCE_WEIGHT}, è´¨é‡é˜ˆå€¼={QUALITY_THRESHOLD}")

if __name__ == '__main__':
    main()